{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GautamPoddar18/Melanoma-Detection-Assignment/blob/main/mda_assignment_notebook_(1).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  Melanoma Detection Assignment\n",
        "\n"
      ],
      "metadata": {
        "id": "6u1KbsTg5UXZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Problem statement**: To build a CNN based model which can accurately detect melanoma. Melanoma is a type of cancer that can be deadly if not detected early. It accounts for 75% of skin cancer deaths. A solution that can evaluate images and alert dermatologists about the presence of melanoma has the potential to reduce a lot of manual effort needed in diagnosis."
      ],
      "metadata": {
        "id": "f7plLszr5UXi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Objective: Building a multiclass classification model using a custom CNN in TensorFlow"
      ],
      "metadata": {
        "id": "WVRVOL7X5UXk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data Description**\n",
        "The dataset consists of 2357 images of malignant and benign oncological diseases, which were formed from the International Skin Imaging Collaboration (ISIC). All images were sorted according to the classification taken with ISIC, and all subsets were divided into the same number of images, with the exception of melanomas and moles, whose images are slightly dominant.\n",
        "\n",
        "The data set contains the following diseases:\n",
        "\n",
        "1. Actinic keratosis\n",
        "2. Basal cell carcinoma\n",
        "3. Dermatofibroma\n",
        "4. Melanoma\n",
        "5. Nevus\n",
        "6. Pigmented benign keratosis\n",
        "7. Seborrheic keratosis\n",
        "8. Squamous cell carcinoma\n",
        "9. Vascular lesion\n",
        "\n",
        "Dataset link: https://drive.google.com/file/d/1xLfSQUGDl8ezNNbUkpuHOYvSpTyxVhCs/"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-11-20T10:08:27.432099Z",
          "iopub.status.busy": "2022-11-20T10:08:27.431397Z",
          "iopub.status.idle": "2022-11-20T10:08:27.468208Z",
          "shell.execute_reply": "2022-11-20T10:08:27.466105Z",
          "shell.execute_reply.started": "2022-11-20T10:08:27.431952Z"
        },
        "id": "1v0EzMrZ5UXl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Project Pipeline"
      ],
      "metadata": {
        "id": "RJlHXw4P5UXm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Importing Libraries\n",
        "\n",
        "import pathlib\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import PIL\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-11-21T20:26:39.533415Z",
          "iopub.execute_input": "2022-11-21T20:26:39.533797Z",
          "iopub.status.idle": "2022-11-21T20:26:39.542357Z",
          "shell.execute_reply.started": "2022-11-21T20:26:39.533769Z",
          "shell.execute_reply": "2022-11-21T20:26:39.541007Z"
        },
        "trusted": true,
        "id": "-TNiAbCz5UXm"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-11-21T20:26:42.112706Z",
          "iopub.execute_input": "2022-11-21T20:26:42.113748Z",
          "iopub.status.idle": "2022-11-21T20:26:42.121058Z",
          "shell.execute_reply.started": "2022-11-21T20:26:42.113710Z",
          "shell.execute_reply": "2022-11-21T20:26:42.120011Z"
        },
        "trusted": true,
        "id": "PyA_5aQ_5UXp"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow.keras.preprocessing as pre"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-11-21T20:26:44.361563Z",
          "iopub.execute_input": "2022-11-21T20:26:44.361933Z",
          "iopub.status.idle": "2022-11-21T20:26:44.367305Z",
          "shell.execute_reply.started": "2022-11-21T20:26:44.361903Z",
          "shell.execute_reply": "2022-11-21T20:26:44.366020Z"
        },
        "trusted": true,
        "id": "HhdSq9YJ5UXq"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Data Reading/Data Understanding"
      ],
      "metadata": {
        "id": "0vIQ6EER5UXs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## If you are using the data by mounting the google drive, use the following :\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "drive_path = '/content/gdrive/My Drive/Machine Learning/Melanoma Detection Assignment/CNN_assignment/Skin cancer ISIC The International Skin Imaging Collaboration/'\n",
        "## Defining Path Variable in goggle Colab\n",
        "path_train = pathlib.Path(drive_path + \"Train\")\n",
        "path_test = pathlib.Path(drive_path + \"Test\")\n",
        "## Image Count\n",
        "train_count = len(list(path_train.glob('*/*.jpg')))\n",
        "print('Train Image Count', train_count)\n",
        "test_count = len(list(path_test.glob('*/*.jpg')))\n",
        "print('Test Image Count',test_count)"
      ],
      "metadata": {
        "id": "5NXDbcMi5f8X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef011396-f5ef-429a-9692-5a3d4f3cb327"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n",
            "Train Image Count 2239\n",
            "Test Image Count 118\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "\n",
        "## Defining Path Variable in kaggle\n",
        "path_train = pathlib.Path(\"../input/skin-cancer/Skin cancer ISIC The International Skin Imaging Collaboration/Train\")\n",
        "path_test = pathlib.Path('../input/skin-cancer/Skin cancer ISIC The International Skin Imaging Collaboration/Test')\n",
        "## Image Count\n",
        "train_count = len(list(path_train.glob('*/*.jpg')))\n",
        "print('Train Image Count', train_count)\n",
        "test_count = len(list(path_test.glob('*/*.jpg')))\n",
        "print('Test Image Count',test_count)\n",
        "\n",
        "'''"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-11-21T20:26:49.087192Z",
          "iopub.execute_input": "2022-11-21T20:26:49.087963Z",
          "iopub.status.idle": "2022-11-21T20:26:49.092550Z",
          "shell.execute_reply.started": "2022-11-21T20:26:49.087921Z",
          "shell.execute_reply": "2022-11-21T20:26:49.091363Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "PRLnE2c35UXu",
        "outputId": "bf5377fe-7865-4894-c53c-e8040f3442aa"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n\\n## Defining Path Variable in kaggle\\npath_train = pathlib.Path(\"../input/skin-cancer/Skin cancer ISIC The International Skin Imaging Collaboration/Train\")\\npath_test = pathlib.Path(\\'../input/skin-cancer/Skin cancer ISIC The International Skin Imaging Collaboration/Test\\')\\n## Image Count\\ntrain_count = len(list(path_train.glob(\\'*/*.jpg\\')))\\nprint(\\'Train Image Count\\', train_count)\\ntest_count = len(list(path_test.glob(\\'*/*.jpg\\')))\\nprint(\\'Test Image Count\\',test_count)\\n\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Dataset creation"
      ],
      "metadata": {
        "id": "IY4kmy2r5UXx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Creating the Dataset"
      ],
      "metadata": {
        "id": "kOELkj0S5UXx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "img_height = 180\n",
        "img_width = 180"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-11-21T20:27:01.024040Z",
          "iopub.execute_input": "2022-11-21T20:27:01.024646Z",
          "iopub.status.idle": "2022-11-21T20:27:01.029535Z",
          "shell.execute_reply.started": "2022-11-21T20:27:01.024608Z",
          "shell.execute_reply": "2022-11-21T20:27:01.028368Z"
        },
        "trusted": true,
        "id": "Gd0VD85O5UXy"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Keeping 70/30 Train and Validation Dataset Ratio and using seed=123"
      ],
      "metadata": {
        "id": "XsR5iFiY5UXz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Writing Train dataset\n",
        "train_ds = pre.image_dataset_from_directory(\n",
        "    path_train,\n",
        "    seed=123,\n",
        "    validation_split= 0.3,\n",
        "    subset= 'training',\n",
        "    image_size=(img_height,img_width),\n",
        "    batch_size = batch_size\n",
        ")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-11-21T20:27:02.839259Z",
          "iopub.execute_input": "2022-11-21T20:27:02.839698Z",
          "iopub.status.idle": "2022-11-21T20:27:05.540871Z",
          "shell.execute_reply.started": "2022-11-21T20:27:02.839654Z",
          "shell.execute_reply": "2022-11-21T20:27:05.539738Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r5gmYOMc5UX0",
        "outputId": "e1db098d-8967-4133-a8bf-b4f389fcaab2"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 3866 files belonging to 9 classes.\n",
            "Using 2707 files for training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Writing Validation dataset\n",
        "val_ds = pre.image_dataset_from_directory(\n",
        "    path_train,\n",
        "    seed=123,\n",
        "    validation_split= 0.3,\n",
        "    subset= 'validation',\n",
        "    image_size=(img_height,img_width),\n",
        "    batch_size = batch_size\n",
        ")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-11-21T20:27:05.542734Z",
          "iopub.execute_input": "2022-11-21T20:27:05.543322Z",
          "iopub.status.idle": "2022-11-21T20:27:05.778087Z",
          "shell.execute_reply.started": "2022-11-21T20:27:05.543266Z",
          "shell.execute_reply": "2022-11-21T20:27:05.777055Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w4ISfXVa5UX1",
        "outputId": "006fcf6d-e968-4d8a-80ae-72f292e2a48e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 3866 files belonging to 9 classes.\n",
            "Using 1159 files for validation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Writing Test dataset\n",
        "test_ds = pre.image_dataset_from_directory(\n",
        "    path_test,\n",
        "    seed=123,\n",
        "    image_size=(img_height,img_width),\n",
        "    batch_size = batch_size\n",
        ")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-11-21T20:27:06.140957Z",
          "iopub.execute_input": "2022-11-21T20:27:06.141273Z",
          "iopub.status.idle": "2022-11-21T20:27:06.261393Z",
          "shell.execute_reply.started": "2022-11-21T20:27:06.141245Z",
          "shell.execute_reply": "2022-11-21T20:27:06.260351Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eSFIZr7l5UX2",
        "outputId": "83325022-1403-4c60-b459-2acffe06f3a2"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 118 files belonging to 9 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Train Dataset Class Names :\\n\",train_ds.class_names)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-11-21T20:02:59.722258Z",
          "iopub.execute_input": "2022-11-21T20:02:59.722596Z",
          "iopub.status.idle": "2022-11-21T20:02:59.727796Z",
          "shell.execute_reply.started": "2022-11-21T20:02:59.722560Z",
          "shell.execute_reply": "2022-11-21T20:02:59.726323Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3XOgX2Lx5UX4",
        "outputId": "d59946b5-74fa-4e52-fb26-709db7a1f6d9"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Dataset Class Names :\n",
            " ['actinic keratosis', 'basal cell carcinoma', 'dermatofibroma', 'melanoma', 'nevus', 'pigmented benign keratosis', 'seborrheic keratosis', 'squamous cell carcinoma', 'vascular lesion']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Train Dataset Class Names :\\n\",test_ds.class_names)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-11-21T20:03:01.694538Z",
          "iopub.execute_input": "2022-11-21T20:03:01.694866Z",
          "iopub.status.idle": "2022-11-21T20:03:01.699909Z",
          "shell.execute_reply.started": "2022-11-21T20:03:01.694833Z",
          "shell.execute_reply": "2022-11-21T20:03:01.699007Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iTCzYp_c5UX5",
        "outputId": "679b87b3-5ccc-430d-8469-810ec722f63e"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Dataset Class Names :\n",
            " ['actinic keratosis', 'basal cell carcinoma', 'dermatofibroma', 'melanoma', 'nevus', 'pigmented benign keratosis', 'seborrheic keratosis', 'squamous cell carcinoma', 'vascular lesion']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Dataset visualisation"
      ],
      "metadata": {
        "id": "7vXrkQRD5UX7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_classes = train_ds.class_names\n",
        "test_dataset_classes = test_ds.class_names"
      ],
      "metadata": {
        "trusted": true,
        "id": "UkQkNuaO5UX9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.image as mpimg\n",
        "plt.figure(figsize=(10,10))\n",
        "for i in range(9): \n",
        "  plt.subplot(3, 3, i + 1)\n",
        "  image = mpimg.imread(str(list(path_train.glob(dataset_classes[i]+'/*.jpg'))[1]))\n",
        "  plt.title(dataset_classes[i])\n",
        "  plt.imshow(image)"
      ],
      "metadata": {
        "trusted": true,
        "id": "iCRC-K4V5UX-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test dataset visualization\n",
        "plt.figure(figsize=(10,10))\n",
        "for i in range(9): \n",
        "  plt.subplot(3, 3, i + 1)\n",
        "  image = mpimg.imread(str(list(path_test.glob(test_dataset_classes[i]+'/*.jpg'))[1]))\n",
        "  plt.title(test_dataset_classes[i])\n",
        "  plt.imshow(image)"
      ],
      "metadata": {
        "trusted": true,
        "id": "ldHRQt2W5UX-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The `image_batch` is a tensor of the shape `(32, 180, 180, 3)`. This is a batch of 32 images of shape `180x180x3` (the last dimension refers to color channels RGB). The `label_batch` is a tensor of the shape `(32,)`, these are corresponding labels to the 32 images.\n",
        "\n"
      ],
      "metadata": {
        "id": "kjHtrzg15UX_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`Dataset.cache()` keeps the images in memory after they're loaded off disk during the first epoch.\n",
        "\n",
        "`Dataset.prefetch()` overlaps data preprocessing and model execution while training."
      ],
      "metadata": {
        "id": "sPNxq6nT5UX_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
        "train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
        "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
      ],
      "metadata": {
        "trusted": true,
        "id": "pNSseaF25UYA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Model Building & training"
      ],
      "metadata": {
        "id": "vWnpbGbj5UYA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Model 1"
      ],
      "metadata": {
        "id": "THmFv8Hz5UYA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D"
      ],
      "metadata": {
        "trusted": true,
        "id": "X77ReME35UYB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Model Defination\n",
        "num_classes = 9\n",
        "model = Sequential([\n",
        "                    layers.experimental.preprocessing.Rescaling(1./255, input_shape=(img_height, img_width,3))\n",
        "])\n",
        "model.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n",
        "                 activation ='relu', input_shape = (180, 180, 32)))\n",
        "model.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n",
        "                 activation ='relu'))\n",
        "model.add(MaxPool2D(pool_size=(2,2)))\n",
        "model.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n",
        "                 activation ='relu'))\n",
        "model.add(MaxPool2D(pool_size=(2,2)))\n",
        "model.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n",
        "                 activation ='relu'))\n",
        "model.add(MaxPool2D(pool_size=(2,2)))\n",
        "model.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n",
        "                 activation ='relu'))\n",
        "model.add(MaxPool2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(num_classes, activation = \"softmax\"))"
      ],
      "metadata": {
        "trusted": true,
        "id": "ex6oKls25UYB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Model Compile\n",
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "trusted": true,
        "id": "o9Z6yKXs5UYC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## View the summary of all layers\n",
        "model.summary()"
      ],
      "metadata": {
        "trusted": true,
        "id": "OfYPoZpe5UYC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Model Training\n",
        "epochs=10\n",
        "history = model.fit(\n",
        "  train_ds,\n",
        "  validation_data=val_ds,\n",
        "  epochs=epochs\n",
        ")"
      ],
      "metadata": {
        "trusted": true,
        "id": "cODYwxCP5UYC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Visualizing Training Results\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_range = range(epochs)\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "id": "Tkdoz6Tj5UYD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Since no pattern observed, increasing the number of epochs to 30 for observation**"
      ],
      "metadata": {
        "id": "ecRNnUUh5UYD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Model Training Epoch =20\n",
        "epochs=20\n",
        "history_epoch20 = model.fit(\n",
        "  train_ds,\n",
        "  validation_data=val_ds,\n",
        "  epochs=epochs\n",
        ")"
      ],
      "metadata": {
        "trusted": true,
        "id": "fXuKy2EG5UYE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Visualizing Training Results\n",
        "acc = history_epoch20.history['accuracy']\n",
        "val_acc = history_epoch20.history['val_accuracy']\n",
        "\n",
        "loss = history_epoch20.history['loss']\n",
        "val_loss = history_epoch20.history['val_loss']\n",
        "\n",
        "epochs_range = range(epochs)\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "id": "crv3ibK05UYE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Intial Findings**\n",
        "There is overfitting observed in the model as validation accuracy decreases while train accuracy increases around 17th epoch"
      ],
      "metadata": {
        "id": "0OAROMMU5UYF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Test dataset Prediction and Accuracy\n",
        "y_true=[]\n",
        "y_pred=[]\n",
        "for images, labels in test_ds.take(1):\n",
        "  # print(model.predict_classes(images))\n",
        "  # print(labels.numpy())\n",
        "  y_true=list(labels.numpy())\n",
        "  y_pred=model.predict_classes(images)\n",
        "  # break\n",
        "print(classification_report(y_true,y_pred,target_names=dataset_classes))\n",
        "print(\"------\"*20)\n",
        "print(\"Accuracy on test dataset : \",(accuracy_score(y_true,y_pred)*100      )         )"
      ],
      "metadata": {
        "trusted": true,
        "id": "_8BsMyNV5UYF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Using a RMSprop Optimizers"
      ],
      "metadata": {
        "id": "CtYswFk05UYG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Model Defination\n",
        "num_classes = 9\n",
        "model_rmsprop = Sequential([\n",
        "                    layers.experimental.preprocessing.Rescaling(1./255, input_shape=(img_height, img_width,3))\n",
        "])\n",
        "model_rmsprop.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n",
        "                 activation ='relu', input_shape = (180, 180, 32)))\n",
        "model_rmsprop.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n",
        "                 activation ='relu'))\n",
        "model_rmsprop.add(MaxPool2D(pool_size=(2,2)))\n",
        "model_rmsprop.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n",
        "                 activation ='relu'))\n",
        "model_rmsprop.add(MaxPool2D(pool_size=(2,2)))\n",
        "model_rmsprop.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n",
        "                 activation ='relu'))\n",
        "model_rmsprop.add(MaxPool2D(pool_size=(2,2)))\n",
        "model_rmsprop.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n",
        "                 activation ='relu'))\n",
        "model_rmsprop.add(MaxPool2D(pool_size=(2,2)))\n",
        "model_rmsprop.add(Dropout(0.25))\n",
        "\n",
        "\n",
        "model_rmsprop.add(Flatten())\n",
        "model_rmsprop.add(Dense(num_classes, activation = \"softmax\"))\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "4MquFrqP5UYG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Model Compile\n",
        "model_rmsprop.compile(optimizer='rmsprop',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "trusted": true,
        "id": "a865uA-_5UYH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## View the summary of all layers\n",
        "model_rmsprop.summary()"
      ],
      "metadata": {
        "trusted": true,
        "id": "2ReH3t6n5UYJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Model Training\n",
        "epochs=20\n",
        "history_rmsprop = model_rmsprop.fit(\n",
        "  train_ds,\n",
        "  validation_data=val_ds,\n",
        "  epochs=epochs\n",
        ")"
      ],
      "metadata": {
        "trusted": true,
        "id": "hrKy5aUi5UYJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Visualizing Training Results\n",
        "acc = history_rmsprop.history['accuracy']\n",
        "val_acc = history_rmsprop.history['val_accuracy']\n",
        "\n",
        "loss = history_rmsprop.history['loss']\n",
        "val_loss = history_rmsprop.history['val_loss']\n",
        "\n",
        "epochs_range = range(epochs)\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "id": "QVtD2v9B5UYK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Test dataset Prediction and Accuracy\n",
        "y_true=[]\n",
        "y_pred=[]\n",
        "for images, labels in test_ds.take(1):\n",
        "  # print(model.predict_classes(images))\n",
        "  # print(labels.numpy())\n",
        "  y_true=list(labels.numpy())\n",
        "  y_pred=model_rmsprop.predict_classes(images)\n",
        "  # break\n",
        "print(classification_report(y_true,y_pred,target_names=dataset_classes))\n",
        "print(\"------\"*20)\n",
        "print(\"Accuracy on test dataset : \",(accuracy_score(y_true,y_pred)*100      )         )"
      ],
      "metadata": {
        "trusted": true,
        "id": "TDHIOc3I5UYK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Observation: No major improvement in Accuracy**"
      ],
      "metadata": {
        "id": "hc670i9N5UYL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Data augmentation"
      ],
      "metadata": {
        "id": "IThEsCLK5UYM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_aug = keras.Sequential([\n",
        "                             layers.experimental.preprocessing.RandomFlip(mode=\"horizontal_and_vertical\",input_shape=(img_height,img_width,3)),\n",
        "                             layers.experimental.preprocessing.RandomRotation(0.2, fill_mode='reflect'),\n",
        "                             layers.experimental.preprocessing.RandomZoom(height_factor=(0.2, 0.3), width_factor=(0.2, 0.3), fill_mode='reflect')\n",
        "])"
      ],
      "metadata": {
        "trusted": true,
        "id": "ow_DOvIo5UYM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# visualize how your augmentation strategy works for one instance of training image.\n",
        "plt.figure(figsize=(12, 12))\n",
        "for images, labels in train_ds.take(1):\n",
        "    for i in range(9):\n",
        "        ax = plt.subplot(3, 3, i + 1)\n",
        "        plt.imshow(data_aug(images)[i].numpy().astype(\"uint8\"))\n",
        "        plt.title(dataset_classes[labels[i]])\n",
        "        plt.axis(\"off\")"
      ],
      "metadata": {
        "trusted": true,
        "id": "eVeonW4a5UYN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6. Model Building & training on Augmented Data"
      ],
      "metadata": {
        "id": "RA01h39k5UYN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Model 2"
      ],
      "metadata": {
        "id": "WDSuQGv45UYN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\\"
      ],
      "metadata": {
        "trusted": true,
        "id": "3eHYTxCp5UYO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Model Building on Augmented Data using Adam Optimizer"
      ],
      "metadata": {
        "id": "0b_u2xX45UYO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " \n",
        "num_classes = 9\n",
        "model_aug_adam = Sequential([ data_aug,\n",
        "                    layers.experimental.preprocessing.Rescaling(1./255, input_shape=(img_height, img_width,3))\n",
        "      \n",
        "])\n",
        "model_aug_adam.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n",
        "                 activation ='relu', input_shape = (180, 180, 32)))\n",
        "model_aug_adam.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n",
        "                 activation ='relu'))\n",
        "model_aug_adam.add(MaxPool2D(pool_size=(2,2)))\n",
        "model_aug_adam.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n",
        "                 activation ='relu'))\n",
        "model_aug_adam.add(MaxPool2D(pool_size=(2,2)))\n",
        "model_aug_adam.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n",
        "                 activation ='relu'))\n",
        "model_aug_adam.add(MaxPool2D(pool_size=(2,2)))\n",
        "model_aug_adam.add(Dropout(0.25))\n",
        "\n",
        "\n",
        "model_aug_adam.add(Flatten())\n",
        "model_aug_adam.add(Dense(num_classes, activation = \"softmax\"))\n",
        "\n",
        "## Model 2 Compilation\n",
        "model_aug_adam.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "## Model 2 Training\n",
        "epochs=30\n",
        "history_aug_adam = model_aug_adam.fit(\n",
        "  train_ds,\n",
        "  validation_data=val_ds,\n",
        "  epochs=epochs\n",
        ")"
      ],
      "metadata": {
        "trusted": true,
        "id": "T-ogS9BL5UYO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model 2 Visualizaiton\n",
        "acc = history_aug_adam.history['accuracy']\n",
        "val_acc = history_aug_adam.history['val_accuracy']\n",
        "\n",
        "loss = history_aug_adam.history['loss']\n",
        "val_loss = history_aug_adam.history['val_loss']\n",
        "\n",
        "epochs_range = range(epochs)\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "id": "WIGr9gEq5UYP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Observation: Overfitting and loss both reduce in this model**"
      ],
      "metadata": {
        "id": "6emtrF555UYP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Model Building on Augmented Data using Stochastic gradient descent(SGD) Optimizer"
      ],
      "metadata": {
        "id": "RV4br1tm5UYQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " \n",
        "num_classes = 9\n",
        "model_aug_SGD = Sequential([ data_aug,\n",
        "                    layers.experimental.preprocessing.Rescaling(1./255, input_shape=(img_height, img_width,3))\n",
        "      \n",
        "])\n",
        "model_aug_SGD.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n",
        "                 activation ='relu', input_shape = (180, 180, 32)))\n",
        "model_aug_SGD.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n",
        "                 activation ='relu'))\n",
        "model_aug_SGD.add(MaxPool2D(pool_size=(2,2)))\n",
        "model_aug_SGD.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n",
        "                 activation ='relu'))\n",
        "model_aug_SGD.add(MaxPool2D(pool_size=(2,2)))\n",
        "model_aug_SGD.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n",
        "                 activation ='relu'))\n",
        "model_aug_SGD.add(MaxPool2D(pool_size=(2,2)))\n",
        "model_aug_SGD.add(Dropout(0.25))\n",
        "\n",
        "\n",
        "model_aug_SGD.add(Flatten())\n",
        "model_aug_SGD.add(Dense(num_classes, activation = \"softmax\"))\n",
        "\n",
        "## Model Compilation\n",
        "model_aug_SGD.compile(optimizer='sgd',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "## Model 2 Training\n",
        "epochs=30\n",
        "history_aug_sgd = model_aug_SGD.fit(\n",
        "  train_ds,\n",
        "  validation_data=val_ds,\n",
        "  epochs=epochs\n",
        ")"
      ],
      "metadata": {
        "trusted": true,
        "id": "wAyyH9cp5UYQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model 2 Visualizaiton\n",
        "acc = history_aug_sgd.history['accuracy']\n",
        "val_acc = history_aug_sgd.history['val_accuracy']\n",
        "\n",
        "loss = history_aug_sgd.history['loss']\n",
        "val_loss = history_aug_sgd.history['val_loss']\n",
        "\n",
        "epochs_range = range(epochs)\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "id": "SxlGRBda5UYQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Model Building on Augmented Data using Adagrad Optimizer"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-11-21T19:26:15.479083Z",
          "iopub.execute_input": "2022-11-21T19:26:15.479436Z",
          "iopub.status.idle": "2022-11-21T19:26:15.483716Z",
          "shell.execute_reply.started": "2022-11-21T19:26:15.479401Z",
          "shell.execute_reply": "2022-11-21T19:26:15.482557Z"
        },
        "id": "RoSgWx-05UYR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " \n",
        "num_classes = 9\n",
        "model_aug_adagrad = Sequential([ data_aug,\n",
        "                    layers.experimental.preprocessing.Rescaling(1./255, input_shape=(img_height, img_width,3))\n",
        "      \n",
        "])\n",
        "model_aug_adagrad.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n",
        "                 activation ='relu', input_shape = (180, 180, 32)))\n",
        "model_aug_adagrad.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n",
        "                 activation ='relu'))\n",
        "model_aug_adagrad.add(MaxPool2D(pool_size=(2,2)))\n",
        "model_aug_adagrad.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n",
        "                 activation ='relu'))\n",
        "model_aug_adagrad.add(MaxPool2D(pool_size=(2,2)))\n",
        "model_aug_adagrad.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n",
        "                 activation ='relu'))\n",
        "model_aug_adagrad.add(MaxPool2D(pool_size=(2,2)))\n",
        "model_aug_adagrad.add(Dropout(0.25))\n",
        "\n",
        "\n",
        "model_aug_adagrad.add(Flatten())\n",
        "model_aug_adagrad.add(Dense(num_classes, activation = \"softmax\"))\n",
        "\n",
        "## Model Compilation\n",
        "model_aug_adagrad.compile(optimizer='adagrad',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "## Model 2 Training\n",
        "epochs=30\n",
        "history_aug_adagrad = model_aug_adagrad.fit(\n",
        "  train_ds,\n",
        "  validation_data=val_ds,\n",
        "  epochs=epochs\n",
        ")"
      ],
      "metadata": {
        "trusted": true,
        "id": "eMUfQzZF5UYR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model 2 Visualizaiton\n",
        "acc = history_aug_adagrad.history['accuracy']\n",
        "val_acc = history_aug_adagrad.history['val_accuracy']\n",
        "\n",
        "loss = history_aug_adagrad.history['loss']\n",
        "val_loss = history_aug_adagrad.history['val_loss']\n",
        "\n",
        "epochs_range = range(epochs)\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "id": "WfoqkGjk5UYS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Augmented Models Predication on Test Dataset"
      ],
      "metadata": {
        "id": "AV7HUq_k5UYT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#checking the performance on the test set \n",
        "y_true=[]\n",
        "y_pred=[]\n",
        "for images, labels in test_ds.take(1):\n",
        "  y_true=list(labels.numpy())\n",
        "  y_pred=model_aug_adam.predict_classes(images)\n",
        "  # break\n",
        "  print(\"Adam optimizer\")\n",
        "  print(classification_report(y_true,y_pred,target_names=dataset_classes))\n",
        "  print(\"Accuracy on test dataset : \",accuracy_score(y_true,y_pred))\n",
        "  \n",
        "\n",
        "  print(\"*\"*20)\n",
        "  y_pred=model_aug_adagrad.predict_classes(images)\n",
        "  # break\n",
        "  print(\"Adagrad optimizer\")\n",
        "  print(classification_report(y_true,y_pred,target_names=dataset_classes))\n",
        "  print(\"Accuracy on test dataset : \",accuracy_score(y_true,y_pred))\n",
        "  \n",
        "    \n",
        "  print(\"*\"*20)\n",
        "  y_pred=model_aug_SGD.predict_classes(images)\n",
        "  # break\n",
        "  print(\"SGD optimizer\")\n",
        "  print(classification_report(y_true,y_pred,target_names=dataset_classes))\n",
        "  print(\"Accuracy on test dataset : \",accuracy_score(y_true,y_pred))\n",
        "  print(\"*\"*20)"
      ],
      "metadata": {
        "trusted": true,
        "id": "lrvOuEFJ5UYU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Findings** \n",
        "1. After addition of Agumentation layers we were able to reduce the model's overfitting. However in this case the model is not able to generalise well. \n",
        "2. We tried out different set of optmizers sgd , adagrad , adams which gave models that had low Training and Validation accuracy. \n",
        "3. The accuracy figures were less than 50% both for training and validation.\n",
        "4. Maximum Accuracy on Test Dataset we were able to achive was 46%"
      ],
      "metadata": {
        "id": "Z5L4taTA5UYW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7. Class distribution"
      ],
      "metadata": {
        "id": "tKrZKt575UYX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path_list=[]\n",
        "lesion_list=[]\n",
        "for i in dataset_classes:\n",
        "      \n",
        "    for j in path_train.glob(i+'/*.jpg'):\n",
        "        path_list.append(str(j))\n",
        "        lesion_list.append(i)\n",
        "dataframe_dict_original = dict(zip(path_list, lesion_list))\n",
        "original_df = pd.DataFrame(list(dataframe_dict_original.items()),columns = ['Path','Label'])\n",
        "original_df.head()"
      ],
      "metadata": {
        "trusted": true,
        "id": "XsqsK9d05UYX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataframe_dict_original = dict(zip(path_list, lesion_list))\n",
        "original_df = pd.DataFrame(list(dataframe_dict_original.items()),columns = ['Path','Label'])\n",
        "original_df.head()"
      ],
      "metadata": {
        "trusted": true,
        "id": "XspXYmbC5UYX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "count=[]\n",
        "for i in dataset_classes:\n",
        "    count.append(len(list(path_train.glob(i+'/*.jpg'))))\n",
        "plt.figure(figsize=(25,10))\n",
        "plt.bar(dataset_classes,count)"
      ],
      "metadata": {
        "trusted": true,
        "id": "BonbG7zY5UYY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_classes"
      ],
      "metadata": {
        "trusted": true,
        "id": "RgLlTKex5UYY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Observation\n",
        "* Highest Distribution Class: pigmented benign keratosis\n",
        "* Lowest Distribution Class: seborrheic keratosis"
      ],
      "metadata": {
        "id": "nunTkYrr5UYf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 8. Handling class imbalances"
      ],
      "metadata": {
        "id": "tTriyNvb5UYf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install Augmentor"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-11-21T20:25:42.062519Z",
          "iopub.execute_input": "2022-11-21T20:25:42.063606Z",
          "iopub.status.idle": "2022-11-21T20:25:52.235377Z",
          "shell.execute_reply.started": "2022-11-21T20:25:42.063568Z",
          "shell.execute_reply": "2022-11-21T20:25:52.234163Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4SrZ5FVV5UYg",
        "outputId": "44085f2c-3d46-45e2-dbdc-381b91908bc5"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting Augmentor\n",
            "  Downloading Augmentor-0.2.10-py2.py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from Augmentor) (1.21.6)\n",
            "Requirement already satisfied: Pillow>=5.2.0 in /usr/local/lib/python3.7/dist-packages (from Augmentor) (7.1.2)\n",
            "Requirement already satisfied: future>=0.16.0 in /usr/local/lib/python3.7/dist-packages (from Augmentor) (0.16.0)\n",
            "Requirement already satisfied: tqdm>=4.9.0 in /usr/local/lib/python3.7/dist-packages (from Augmentor) (4.64.1)\n",
            "Installing collected packages: Augmentor\n",
            "Successfully installed Augmentor-0.2.10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import Augmentor"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-11-21T20:26:03.202576Z",
          "iopub.execute_input": "2022-11-21T20:26:03.203006Z",
          "iopub.status.idle": "2022-11-21T20:26:03.226277Z",
          "shell.execute_reply.started": "2022-11-21T20:26:03.202969Z",
          "shell.execute_reply": "2022-11-21T20:26:03.225406Z"
        },
        "trusted": true,
        "id": "hzJQqw4V5UYh"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from glob import glob"
      ],
      "metadata": {
        "id": "kBSdONw08o4r"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To use `Augmentor`, the following general procedure is followed:\n",
        "\n",
        "1. Instantiate a `Pipeline` object pointing to a directory containing your initial image data set.<br>\n",
        "2. Define a number of operations to perform on this data set using your `Pipeline` object.<br>\n",
        "3. Execute these operations by calling the `Pipeline’s` `sample()` method."
      ],
      "metadata": {
        "id": "WNtM2iMr5UYh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path_train"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-11-21T20:26:08.435397Z",
          "iopub.execute_input": "2022-11-21T20:26:08.435756Z",
          "iopub.status.idle": "2022-11-21T20:26:08.444684Z",
          "shell.execute_reply.started": "2022-11-21T20:26:08.435727Z",
          "shell.execute_reply": "2022-11-21T20:26:08.443347Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZNWUTzD_5UYi",
        "outputId": "7b679490-448d-47d4-8c3f-00beaf2d0245"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PosixPath('/content/gdrive/My Drive/Machine Learning/Melanoma Detection Assignment/CNN_assignment/Skin cancer ISIC The International Skin Imaging Collaboration/Train')"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path_to_training_dataset = '/content/gdrive/My Drive/Machine Learning/Melanoma Detection Assignment/CNN_assignment/Skin cancer ISIC The International Skin Imaging Collaboration/Train/'\n",
        "path_to_training_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "XbyHqg1G8_LJ",
        "outputId": "3964c397-0c6b-4550-a3e8-4332f3e70a18"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/gdrive/My Drive/Machine Learning/Melanoma Detection Assignment/CNN_assignment/Skin cancer ISIC The International Skin Imaging Collaboration/Train/'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_classes = train_ds.class_names\n",
        "dataset_classes"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-11-21T20:27:24.164486Z",
          "iopub.execute_input": "2022-11-21T20:27:24.164842Z",
          "iopub.status.idle": "2022-11-21T20:27:24.172225Z",
          "shell.execute_reply.started": "2022-11-21T20:27:24.164812Z",
          "shell.execute_reply": "2022-11-21T20:27:24.171217Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OCxx0nu85UYi",
        "outputId": "51544652-edf4-4a9e-a213-357e656d160a"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['actinic keratosis',\n",
              " 'basal cell carcinoma',\n",
              " 'dermatofibroma',\n",
              " 'melanoma',\n",
              " 'nevus',\n",
              " 'pigmented benign keratosis',\n",
              " 'seborrheic keratosis',\n",
              " 'squamous cell carcinoma',\n",
              " 'vascular lesion']"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in dataset_classes:\n",
        "    p = Augmentor.Pipeline(path_to_training_dataset + i)\n",
        "    p.rotate(probability=0.7, max_left_rotation=10, max_right_rotation=10)\n",
        "    p.sample(500)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ybv4lXxe8cse",
        "outputId": "93f01e46-a404-4890-8e05-d5f071ebc36d"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initialised with 114 image(s) found.\n",
            "Output directory set to /content/gdrive/My Drive/Machine Learning/Melanoma Detection Assignment/CNN_assignment/Skin cancer ISIC The International Skin Imaging Collaboration/Train/actinic keratosis/output."
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing <PIL.Image.Image image mode=RGB size=600x450 at 0x7F9C1CC11F50>: 100%|██████████| 500/500 [00:20<00:00, 24.84 Samples/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initialised with 376 image(s) found.\n",
            "Output directory set to /content/gdrive/My Drive/Machine Learning/Melanoma Detection Assignment/CNN_assignment/Skin cancer ISIC The International Skin Imaging Collaboration/Train/basal cell carcinoma/output."
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=600x450 at 0x7F9C10338610>: 100%|██████████| 500/500 [00:19<00:00, 26.22 Samples/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initialised with 95 image(s) found.\n",
            "Output directory set to /content/gdrive/My Drive/Machine Learning/Melanoma Detection Assignment/CNN_assignment/Skin cancer ISIC The International Skin Imaging Collaboration/Train/dermatofibroma/output."
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing <PIL.Image.Image image mode=RGB size=600x450 at 0x7F9C10380950>: 100%|██████████| 500/500 [00:18<00:00, 26.70 Samples/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initialised with 438 image(s) found.\n",
            "Output directory set to /content/gdrive/My Drive/Machine Learning/Melanoma Detection Assignment/CNN_assignment/Skin cancer ISIC The International Skin Imaging Collaboration/Train/melanoma/output."
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1024x768 at 0x7F9C102EC3D0>: 100%|██████████| 500/500 [01:48<00:00,  4.62 Samples/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initialised with 357 image(s) found.\n",
            "Output directory set to /content/gdrive/My Drive/Machine Learning/Melanoma Detection Assignment/CNN_assignment/Skin cancer ISIC The International Skin Imaging Collaboration/Train/nevus/output."
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing <PIL.Image.Image image mode=RGB size=919x802 at 0x7F9C102F7E90>: 100%|██████████| 500/500 [01:34<00:00,  5.28 Samples/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initialised with 462 image(s) found.\n",
            "Output directory set to /content/gdrive/My Drive/Machine Learning/Melanoma Detection Assignment/CNN_assignment/Skin cancer ISIC The International Skin Imaging Collaboration/Train/pigmented benign keratosis/output."
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing <PIL.Image.Image image mode=RGB size=600x450 at 0x7F9C103B3250>: 100%|██████████| 500/500 [00:22<00:00, 22.63 Samples/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initialised with 77 image(s) found.\n",
            "Output directory set to /content/gdrive/My Drive/Machine Learning/Melanoma Detection Assignment/CNN_assignment/Skin cancer ISIC The International Skin Imaging Collaboration/Train/seborrheic keratosis/output."
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing <PIL.Image.Image image mode=RGB size=1024x768 at 0x7F9C1CD857D0>: 100%|██████████| 500/500 [00:45<00:00, 10.88 Samples/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initialised with 181 image(s) found.\n",
            "Output directory set to /content/gdrive/My Drive/Machine Learning/Melanoma Detection Assignment/CNN_assignment/Skin cancer ISIC The International Skin Imaging Collaboration/Train/squamous cell carcinoma/output."
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing <PIL.Image.Image image mode=RGB size=600x450 at 0x7F9C1E374050>: 100%|██████████| 500/500 [00:20<00:00, 24.42 Samples/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initialised with 139 image(s) found.\n",
            "Output directory set to /content/gdrive/My Drive/Machine Learning/Melanoma Detection Assignment/CNN_assignment/Skin cancer ISIC The International Skin Imaging Collaboration/Train/vascular lesion/output."
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=600x450 at 0x7F9C1CB63B90>: 100%|██████████| 500/500 [00:19<00:00, 26.14 Samples/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image_count_train = len(list(path_train.glob('*/output/*.jpg')))\n",
        "print(image_count_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1w99rwir_IxO",
        "outputId": "0dae0d38-7440-4518-8d66-d45a829187a6"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6127\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IJ5KarKq4kWJ"
      },
      "source": [
        "### 9. Model Building & training on the rectified class imbalance data "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6tODrYIY2nxJ"
      },
      "source": [
        "path_list_new = [x for x in glob(os.path.join(path_train, '*','output', '*.jpg'))]\n",
        "# path_list"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nZvVdF7g3E1z"
      },
      "source": [
        "lesion_list_new = [os.path.basename(os.path.dirname(os.path.dirname(y))) for y in glob(os.path.join(path_train, '*','output', '*.jpg'))]\n",
        "# lesion_list_new"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "okcqVFAA2nxK"
      },
      "source": [
        "dataframe_dict_new = dict(zip(path_list_new, lesion_list_new))"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "njzBxTNT2nxK"
      },
      "source": [
        "df2 = pd.DataFrame(list(dataframe_dict_new.items()),columns = ['Path','Label'])\n",
        "# new_df = original_df.append(df2) "
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5j45rmxd2nxK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d01c72c-a516-443a-a82b-4ffa4200b162"
      },
      "source": [
        "#created 500 samples for each\n",
        "df2['Label'].value_counts()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dermatofibroma                1000\n",
              "actinic keratosis             1000\n",
              "basal cell carcinoma          1000\n",
              "melanoma                       627\n",
              "squamous cell carcinoma        500\n",
              "pigmented benign keratosis     500\n",
              "vascular lesion                500\n",
              "nevus                          500\n",
              "seborrheic keratosis           500\n",
              "Name: Label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_path_list = list(path_train.glob('*/*.jpg'))\n",
        "df=pd.DataFrame({\"cancer_type\":[str(x).split(\"/\")[2] for x in train_path_list]})"
      ],
      "metadata": {
        "id": "0t9gNnNqB0K3"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aoz1aU_CX0tp",
        "outputId": "3ce164a3-a55e-424f-8539-88d88ed53724"
      },
      "source": [
        "#new counts\n",
        "new_list=list(df['cancer_type'].values)\n",
        "new_list.extend(list(df2['Label'].values))\n",
        "len(new_list)\n",
        "final_df=pd.DataFrame({\"cancer_type\":new_list})\n",
        "final_df['cancer_type'].value_counts()"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "gdrive                        2239\n",
              "dermatofibroma                1000\n",
              "actinic keratosis             1000\n",
              "basal cell carcinoma          1000\n",
              "melanoma                       627\n",
              "squamous cell carcinoma        500\n",
              "pigmented benign keratosis     500\n",
              "vascular lesion                500\n",
              "nevus                          500\n",
              "seborrheic keratosis           500\n",
              "Name: cancer_type, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9NirFBvGPmgI"
      },
      "source": [
        "So, now we have added 500 images to all the classes to maintain some class balance. We can add more images as we want to improve training process."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Creating the Dataset after augmentation"
      ],
      "metadata": {
        "id": "yMFqniYLCnRb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "img_height = 180\n",
        "img_width = 180"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-11-21T20:27:01.024040Z",
          "iopub.execute_input": "2022-11-21T20:27:01.024646Z",
          "iopub.status.idle": "2022-11-21T20:27:01.029535Z",
          "shell.execute_reply.started": "2022-11-21T20:27:01.024608Z",
          "shell.execute_reply": "2022-11-21T20:27:01.028368Z"
        },
        "trusted": true,
        "id": "QVozXfMZCnRc"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Keeping 70/30 Train and Validation Dataset Ratio and using seed=123"
      ],
      "metadata": {
        "id": "nwiMpsDeCnRd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Writing Train dataset\n",
        "train_ds_aug = pre.image_dataset_from_directory(\n",
        "    path_train,\n",
        "    seed=123,\n",
        "    validation_split= 0.3,\n",
        "    subset= 'training',\n",
        "    image_size=(img_height,img_width),\n",
        "    batch_size = batch_size\n",
        ")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-11-21T20:27:02.839259Z",
          "iopub.execute_input": "2022-11-21T20:27:02.839698Z",
          "iopub.status.idle": "2022-11-21T20:27:05.540871Z",
          "shell.execute_reply.started": "2022-11-21T20:27:02.839654Z",
          "shell.execute_reply": "2022-11-21T20:27:05.539738Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5141795-37b1-412e-d15f-0180456fa58b",
        "id": "cTQxdz9pCnRe"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 8366 files belonging to 9 classes.\n",
            "Using 5857 files for training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Writing Validation dataset\n",
        "val_ds_aug = pre.image_dataset_from_directory(\n",
        "    path_train,\n",
        "    seed=123,\n",
        "    validation_split= 0.3,\n",
        "    subset= 'validation',\n",
        "    image_size=(img_height,img_width),\n",
        "    batch_size = batch_size\n",
        ")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-11-21T20:27:05.542734Z",
          "iopub.execute_input": "2022-11-21T20:27:05.543322Z",
          "iopub.status.idle": "2022-11-21T20:27:05.778087Z",
          "shell.execute_reply.started": "2022-11-21T20:27:05.543266Z",
          "shell.execute_reply": "2022-11-21T20:27:05.777055Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aabd9904-f56c-4beb-86a6-39efea9b0ff4",
        "id": "MTV20sAXCnRf"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 8366 files belonging to 9 classes.\n",
            "Using 2509 files for validation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Model Building & training on Augmented Data and Class Imblance handling"
      ],
      "metadata": {
        "id": "HA1sO9qMDr77"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\\"
      ],
      "metadata": {
        "trusted": true,
        "id": "QPkcEkUdDr79"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Model Building on Augmented Data using Adam Optimizer"
      ],
      "metadata": {
        "id": "jaGqrwqRDr79"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = 9\n",
        "model_aug_adam = Sequential([\n",
        "                    layers.experimental.preprocessing.Rescaling(1./255, input_shape=(img_height, img_width,3))\n",
        "])\n",
        "model_aug_adam.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n",
        "                 activation ='relu', input_shape = (180, 180, 32)))\n",
        "model_aug_adam.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n",
        "                 activation ='relu'))\n",
        "model_aug_adam.add(MaxPool2D(pool_size=(2,2)))\n",
        "model_aug_adam.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n",
        "                 activation ='relu'))\n",
        "model_aug_adam.add(MaxPool2D(pool_size=(2,2)))\n",
        "model_aug_adam.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n",
        "                 activation ='relu'))\n",
        "model_aug_adam.add(MaxPool2D(pool_size=(2,2)))\n",
        "model_aug_adam.add(Dropout(0.25))\n",
        "\n",
        "\n",
        "model_aug_adam.add(Flatten())\n",
        "model_aug_adam.add(Dense(num_classes, activation = \"softmax\"))\n",
        "\n",
        "## Model 2 Compilation\n",
        "model_aug_adam.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "## Model 2 Training\n",
        "epochs=20\n",
        "history_aug_adam = model_aug_adam.fit(\n",
        "  train_ds_aug,\n",
        "  validation_data=val_ds_aug,\n",
        "  epochs=epochs\n",
        ")"
      ],
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DfQ7fmzUDr7-",
        "outputId": "094e31c8-3f7c-4cac-aa31-95b1501a12d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "184/184 [==============================] - ETA: 0s - loss: 1.9611 - accuracy: 0.2361"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Model 2 Visualizaiton\n",
        "acc = history_aug_adam.history['accuracy']\n",
        "val_acc = history_aug_adam.history['val_accuracy']\n",
        "\n",
        "loss = history_aug_adam.history['loss']\n",
        "val_loss = history_aug_adam.history['val_loss']\n",
        "\n",
        "epochs_range = range(epochs)\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "id": "WHcSL4UHDr7_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Observation: Overfitting and loss both reduce in this model**"
      ],
      "metadata": {
        "id": "gLkG4_TWDr8A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Model Building on Augmented Data using Stochastic gradient descent(SGD) Optimizer"
      ],
      "metadata": {
        "id": "x4oTl-JlDr8A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " \n",
        "num_classes = 9\n",
        "model_aug_SGD = Sequential([\n",
        "                    layers.experimental.preprocessing.Rescaling(1./255, input_shape=(img_height, img_width,3))\n",
        "])\n",
        "model_aug_SGD.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n",
        "                 activation ='relu', input_shape = (180, 180, 32)))\n",
        "model_aug_SGD.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n",
        "                 activation ='relu'))\n",
        "model_aug_SGD.add(MaxPool2D(pool_size=(2,2)))\n",
        "model_aug_SGD.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n",
        "                 activation ='relu'))\n",
        "model_aug_SGD.add(MaxPool2D(pool_size=(2,2)))\n",
        "model_aug_SGD.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n",
        "                 activation ='relu'))\n",
        "model_aug_SGD.add(MaxPool2D(pool_size=(2,2)))\n",
        "model_aug_SGD.add(Dropout(0.25))\n",
        "\n",
        "\n",
        "model_aug_SGD.add(Flatten())\n",
        "model_aug_SGD.add(Dense(num_classes, activation = \"softmax\"))\n",
        "\n",
        "## Model Compilation\n",
        "model_aug_SGD.compile(optimizer='sgd',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "## Model 2 Training\n",
        "epochs=20\n",
        "history_aug_sgd = model_aug_SGD.fit(\n",
        "  train_ds_aug,\n",
        "  validation_data=val_ds_aug,\n",
        "  epochs=epochs\n",
        ")"
      ],
      "metadata": {
        "trusted": true,
        "id": "-U7-UEb3Dr8B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model 2 Visualizaiton\n",
        "acc = history_aug_sgd.history['accuracy']\n",
        "val_acc = history_aug_sgd.history['val_accuracy']\n",
        "\n",
        "loss = history_aug_sgd.history['loss']\n",
        "val_loss = history_aug_sgd.history['val_loss']\n",
        "\n",
        "epochs_range = range(epochs)\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "id": "JAjAOxUeDr8C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Model Building on Augmented Data using Adagrad Optimizer"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-11-21T19:26:15.479083Z",
          "iopub.execute_input": "2022-11-21T19:26:15.479436Z",
          "iopub.status.idle": "2022-11-21T19:26:15.483716Z",
          "shell.execute_reply.started": "2022-11-21T19:26:15.479401Z",
          "shell.execute_reply": "2022-11-21T19:26:15.482557Z"
        },
        "id": "4KpotNeEDr8D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " \n",
        "num_classes = 9\n",
        "model_aug_adagrad = Sequential([\n",
        "                    layers.experimental.preprocessing.Rescaling(1./255, input_shape=(img_height, img_width,3))\n",
        "])\n",
        "model_aug_adagrad.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n",
        "                 activation ='relu', input_shape = (180, 180, 32)))\n",
        "model_aug_adagrad.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n",
        "                 activation ='relu'))\n",
        "model_aug_adagrad.add(MaxPool2D(pool_size=(2,2)))\n",
        "model_aug_adagrad.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n",
        "                 activation ='relu'))\n",
        "model_aug_adagrad.add(MaxPool2D(pool_size=(2,2)))\n",
        "model_aug_adagrad.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n",
        "                 activation ='relu'))\n",
        "model_aug_adagrad.add(MaxPool2D(pool_size=(2,2)))\n",
        "model_aug_adagrad.add(Dropout(0.25))\n",
        "\n",
        "\n",
        "model_aug_adagrad.add(Flatten())\n",
        "model_aug_adagrad.add(Dense(num_classes, activation = \"softmax\"))\n",
        "\n",
        "## Model Compilation\n",
        "model_aug_adagrad.compile(optimizer='adagrad',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "## Model 2 Training\n",
        "epochs=20\n",
        "history_aug_adagrad = model_aug_adagrad.fit(\n",
        "  train_ds_aug,\n",
        "  validation_data=val_ds_aug,\n",
        "  epochs=epochs\n",
        ")"
      ],
      "metadata": {
        "trusted": true,
        "id": "bJK5PQyPDr8E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model 2 Visualizaiton\n",
        "acc = history_aug_adagrad.history['accuracy']\n",
        "val_acc = history_aug_adagrad.history['val_accuracy']\n",
        "\n",
        "loss = history_aug_adagrad.history['loss']\n",
        "val_loss = history_aug_adagrad.history['val_loss']\n",
        "\n",
        "epochs_range = range(epochs)\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "id": "jteIYVBODr8F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Augmented Models Predication on Test Dataset"
      ],
      "metadata": {
        "id": "A48XeEdoDr8F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#checking the performance on the test set \n",
        "y_true=[]\n",
        "y_pred=[]\n",
        "for images, labels in test_ds.take(1):\n",
        "  y_true=list(labels.numpy())\n",
        "  y_pred=model_aug_adam.predict_classes(images)\n",
        "  # break\n",
        "  print(\"Adam optimizer\")\n",
        "  print(classification_report(y_true,y_pred,target_names=dataset_classes))\n",
        "  print(\"Accuracy on test dataset : \",accuracy_score(y_true,y_pred))\n",
        "  \n",
        "\n",
        "  print(\"*\"*20)\n",
        "  y_pred=model_aug_adagrad.predict_classes(images)\n",
        "  # break\n",
        "  print(\"Adagrad optimizer\")\n",
        "  print(classification_report(y_true,y_pred,target_names=dataset_classes))\n",
        "  print(\"Accuracy on test dataset : \",accuracy_score(y_true,y_pred))\n",
        "  \n",
        "    \n",
        "  print(\"*\"*20)\n",
        "  y_pred=model_aug_SGD.predict_classes(images)\n",
        "  # break\n",
        "  print(\"SGD optimizer\")\n",
        "  print(classification_report(y_true,y_pred,target_names=dataset_classes))\n",
        "  print(\"Accuracy on test dataset : \",accuracy_score(y_true,y_pred))\n",
        "  print(\"*\"*20)"
      ],
      "metadata": {
        "trusted": true,
        "id": "AXnzIwTlDr8G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Conculsion\n",
        "\n",
        "1. Adding augmented images helped in handling class imblance.\n",
        "2. Model trained accuracy increased to above 70% and validation above 65%\n",
        "3. Till first 15 epocs learning rate is very high then validation accuracy decreases while train accuracy still increases for some epochs\n"
      ],
      "metadata": {
        "id": "6heQAEt4GJxQ"
      }
    }
  ]
}